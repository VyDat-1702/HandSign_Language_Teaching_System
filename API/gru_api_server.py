from fastapi import FastAPI, Request, WebSocket, WebSocketDisconnect
from websockets.exceptions import ConnectionClosed
from fastapi.templating import Jinja2Templates
import uvicorn
import asyncio
import cv2
import torch
from ultralytics import YOLO
import numpy as np
from decimal import Decimal
from collections import deque
import mediapipe as mp  
import time
from mp import *
import os
os.environ["OMP_NUM_THREADS"] = "4"
# Kh·ªüi t·∫°o FastAPI
app = FastAPI()
# cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)

# T·∫£i model YOLO ch·ªâ m·ªôt l·∫ßn
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
#khai b√°o c√°c classes
class_names = np.array( ["aw","ee","oo","sac", "hoi","nang","nothing","aa","ow","uw", "nga","huyen"])

# log_dir = os.path.join('Logs_file\Logs_8_5\Logs_GRU_8_5')
# tb_callback = TensorBoard(log_dir=log_dir)
# c·∫•u tr√∫c model LSTM
'''
STEP 3: CREATE MODEL CLASS
'''
import torch
import torch.nn as nn

class GRUModel(nn.Module):
    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):
        super(GRUModel, self).__init__()
        
        # GRU layer 1
        self.gru1 = nn.GRU(input_size=input_size, hidden_size=hidden_size1, 
                          batch_first=True)
        self.dropout1 = nn.Dropout(p=0.2)
        
        # GRU layer 2
        self.gru2 = nn.GRU(input_size=hidden_size1, hidden_size=hidden_size2, 
                          batch_first=True)
        self.dropout2 = nn.Dropout(p=0.2)
        
        # Flatten (handled in forward)
        # Dense layer
        self.fc = nn.Linear(hidden_size2 * 30, num_classes)  # 30 l√† seq_len
        
        # Softmax kh√¥ng c·∫ßn khai b√°o ri√™ng v√¨ th∆∞·ªùng x·ª≠ l√Ω trong loss function
        
    def forward(self, x):
        # GRU layer 1
        out, _ = self.gru1(x)  # out: [batch_size, seq_len, hidden_size1]
        out = self.dropout1(out)
        
        # GRU layer 2
        out, _ = self.gru2(out)  # out: [batch_size, seq_len, hidden_size2]
        out = self.dropout2(out)
        
        # Flatten
        out = out.reshape(out.size(0), -1)  # [batch_size, seq_len * hidden_size2]
        
        # Dense layer
        out = self.fc(out)  # [batch_size, num_classes]
        
        return out  # Softmax s·∫Ω ƒë∆∞·ª£c √°p d·ª•ng trong loss (CrossEntropyLoss)
# Kh·ªüi t·∫°o m√¥ h√¨nh
input_size = 63    # S·ªë ƒë·∫∑c tr∆∞ng t·∫°i m·ªói timestep
hidden_size1 = 256 # K√≠ch th∆∞·ªõc hidden state c·ªßa GRU ƒë·∫ßu ti√™n
hidden_size2 = 128 # K√≠ch th∆∞·ªõc hidden state c·ªßa GRU th·ª© hai
num_classes = class_names.shape[0]  # S·ªë l·ªõp ƒë·∫ßu ra (t·ª´ bi·∫øn actions_train)

model = GRUModel(input_size, hidden_size1, hidden_size2, num_classes)  
#compile model 
# max_epoch = 120
# LR = 0.001
# criterion = nn.CrossEntropyLoss()
# optimizer = torch.optim.Adam(model.parameters(), lr=LR)
torch.manual_seed(1)
'''
STEP 4: INSTANTIATE MODEL CLASS
'''




#######################
#  USE GPU FOR MODEL  #
#######################
    
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

# Load tr·ªçng s·ªë m√¥ h√¨nh t·ª´ file ƒë√£ l∆∞u
model.load_state_dict(torch.load('D:/install/AI/Code/Project/GRU_MODEL/gru_model.pth'))

# ƒê·∫∑t m√¥ h√¨nh v√†o ch·∫ø ƒë·ªô ƒë√°nh gi√° (evaluation mode)
model.eval()

# Th√¥ng s·ªë ƒë·∫ßu v√†o
SEQUENCE_LENGTH = 30
PREDICTION_THRESHOLD = 0.5  # Ng∆∞·ª°ng d·ª± ƒëo√°n 50%


templates = Jinja2Templates(directory="templates")

@app.get('/')
def index(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

# H√†m ƒë·ªçc camera async
# async def read_camera():
#     loop = asyncio.get_event_loop()
#     return await loop.run_in_executor(None, cap.read)

@app.websocket("/ws")
async def get_stream(websocket: WebSocket):
    await websocket.accept()
    try:
            while True:
                contents = await websocket.receive_bytes()  # Nh·∫≠n bytes t·ª´ WebSocket
                keypoints = np.frombuffer(contents, dtype=np.float32)  # Decode th√†nh m·∫£ng float32
                print("Keypoints shape before reshape:", keypoints.shape)

                # Chuy·ªÉn th√†nh list 2D c√≥ shape (30, 63)
                keypoints = keypoints.reshape(30, 63).tolist()
                print("Keypoints shape after reshape:", len(keypoints), len(keypoints[0]))  # Ph·∫£i ra (30, 63)


                # üî¥ D·ª± ƒëo√°n
                sequence_tensor = np.expand_dims(keypoints, axis=0)  # Th√™m chi·ªÅu batch
                sequence_tensor = torch.tensor(sequence_tensor, dtype=torch.float32).to(device)
                with torch.no_grad():
        # D·ª± ƒëo√°n
                            res_tensor = model(sequence_tensor)  # G·ªçi m√¥ h√¨nh tr·ª±c ti·∫øp
                            res = torch.softmax(res_tensor[0], dim=-1).cpu().numpy()  # Chuy·ªÉn logits th√†nh x√°c su·∫•t
                            predicted_index = np.argmax(res)
                            prediction_score = res[predicted_index]
                            print(prediction_score)

                
                # Encode ·∫£nh v√† g·ª≠i qua WebSocket
                data = np.array([predicted_index, prediction_score], dtype=np.float32)
                await websocket.send_bytes(data.tobytes())  # 8 bytes n·∫øu 2 ph·∫ßn t·ª≠

                # Gi·∫£m t·∫£i CPU/GPU
                await asyncio.sleep(0.01)  # C√≥ th·ªÉ ch·ªânh 0.01 - 0.05 t√πy t·ªëc ƒë·ªô c·∫ßn thi·∫øt

    except (WebSocketDisconnect, ConnectionClosed):
        print("Client disconnected")

if __name__ == '__main__':
    uvicorn.run(app, host='0.0.0.0', port=8000)
